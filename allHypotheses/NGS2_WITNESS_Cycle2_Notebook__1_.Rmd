---
title: |
  | Group Innovation under Competition and Uncertanity
author: "Pablo Diego-Rosell, PhD  - Gallup"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    number_sections: yes
    theme: united
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
rm(list = ls(all = TRUE))
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, strip.white=TRUE, tidy=TRUE)
```
```{r get_scripts, include=F}
# load libraries

library ("pacman")
library ("formatR")

pacman::p_load(rstan, rstanarm, ggplot2, Hmisc, httr, bridgesampling, DT, dplyr, bayesplot, knitr, lme4, caret, pROC, RCurl, randomForest)
# download scripts and data
dlScripts <- function (scriptNames) {
  fileHolder <- getURL(paste(githubRepo, scriptNames, sep = "/"), ssl.verifypeer = FALSE)
  fileConn<-file(scriptNames)
  writeLines(fileHolder, fileConn)
  close(fileConn)
  }
githubRepo <- "https://raw.githubusercontent.com/GallupGovt/ngs2/master/cycle2/analysis"
scriptNames <- c("run_scripts.r", "effects.R", "wrangle.R", "analytics.R", "merge_empanelment_log.R", 
                 "ActiveLearning_Blocks.R", "positive_controls.R", "h1.1.R", "h1.2.R", "h1.3.R", 
                 "h2.1.R", "h2.2.R", "h2.3.R", "h2.4.R", "h2.5.R", "h2.6.R", "h3.1.R", "h3.2.R", "h3.3.R", 
                 "h3.4.R", "h3.5.R", "gamesData.csv", "empanelment_and_log.csv")
lapply(scriptNames, dlScripts)
```

```{r run_scripts, include=F}
# run scripts in order
# source("run_scripts.r")
# ("run_scripts.r" only run in data wrangling mode - locally)
dd <- getwd()
od <- getwd()
# source effects
source("effects.R")
# set random seed
set.seed(12345)
nIter<-10000
source("analytics.R")
```

# Introduction

Social science has an incoherency problem arising from a historical focus on theory development, which has been recently augmented by a credibility crisis associated with failures in reproducibility, replicability and generalizability of most empirical research. The Gallup WITNESS team proposes advances in each of these areas through the implementation of next generation social science methods, including pre-registration of formalized predictions from multiple models and theories, multifactorial adaptive experiments in immersive environments with large, representative general population samples, probabilistic quantification of multiple sources of uncertainty and fully-transparent and automatically reproducible analytical pipelines. 

To demonstrate and validate these advances, we propose an experimental approach to explore the phenomenon of group motivation to innovate under competition and uncertainty. Evidence from the literature is incoherent regarding the extent to which groups are influenced by uncertainty in their decisions to pursue innovative alternatives, particularly in competitive environments. In this study, we will recruit up to 5,000 participants to participate in a multi-player online gaming platform where they are faced with a resource maximization challenge, which they can tackle using multiple tools and strategies. We will randomize participants according to 14 different variables, in a factorial space with 208 levels to test a total of 32 predictions and compare their explanatory power for group motivation to innovate.  We implement fully-Bayesian inference for hypothesis testing, an active learning pipeline for adaptive experimental design, and machine learning algorithms for data exploration. 

+ Pre-registration form is available at https://osf.io/6frkt/
+ Design and analytic details are available at https://osf.io/g8uv3/

# Active Learning

We deploy and Active Learning approach to minimize posterior uncertainty, where, given a dataset $(x_1,y_1),. ,(x_n,y_n )$, pick a new location $x \epsilon D$ to query the corresponding $x$ such that a large amount of information is gained according to some measure. We prioritize experimental condition based on  measures of variance and entropy. 

```{r active_learning, echo=FALSE}
#source("ActiveLearning_Blocks.R")
```

Sample allocation for subsequent data collection rounds was optimized based on the ranked entropy criterion to adequately power those hypotheses with the greatest information gains. 


# Hypotheses, variables and expected effect sizes

We present next an exhaustive list of confirmatory tests, including all hypotheses and associated predictions, along with the predicted effect sizes used in the priors. As an example, for prediction 1.1.1. variable X_1.1 can take four levels (no competition, low competition, balanced competition, high competition), of which the "no competition" level is the reference category, and the others are hypothesized to have an effect of log odds = -1.45, 1.45, and -1.45 respectively, to align with our prediction that perceived inter-group competition will have a large effect on group motivation to innovate, following an inverse u-shaped relationship. 

```{r hypotheses, echo=FALSE}
tests <- read.csv(url("https://raw.githubusercontent.com/GallupGovt/ngs2/master/cycle2/analysis/Tests.csv"),header = TRUE, sep = ',')
datatable(tests, 
          caption = "Experimental Hypotheses, Variables, and Expected Effect Sizes",
          options = list(
              scrollX = TRUE,
              scrollCollapse = TRUE))
```

# Data used for the prediction

* Valid experimental instances included games with at least three players and one tool choice. 
* Since October 25, 2018, Gallup has: 
    + Ran a total of `r nGames` valid instances.
    + Obtained usable data from a total of `r nPlayers` players.
    + Completed data collection for `r nConditions` of the 208 experimental conditions in the full factorial space.

`r barplot(table(dates$date.time))`

Variables used and a random sample of rows from the final analytical dataset are summarized below. 

```{r data header}
names(factorial)
datatable(sample_n(factorial, 5), 
          caption = "Randomly selected rows of processed data.",
          options = list(
              scrollX = TRUE,
              scrollCollapse = TRUE))
```

# Descriptives
```{r descriptives}
# Number of rounds
nByround=factorial%>%
  group_by(round)%>%
  summarise(counts  = n())
nChoices<-sum(nByround$counts)
nMax<- max(nByround$counts)
ggplot(data=nByround, aes(x=round, y=counts)) +
  geom_bar(stat="identity") +
  ggtitle("Number of Choices") + 
  xlab("Round") +
  ylab("Total Choices by Round")+
  annotate("text", x=7, y=nMax*1.15, label = paste("Total to date =", nChoices, "valid decisions in 13 rounds")) +
  scale_y_continuous(limits = c(0, nMax*1.25))
# By tool choice
factorial.tools<-subset(factorial, tools!="9" & tools!="11" & tools!="12")
factorial.tools$innovation2<- as.numeric(factorial.tools$innovation)-1
tool_rate1<-factorial.tools%>%
  group_by(tools)%>%
  summarise(rate_inn=mean(innovation2, na.rm=TRUE))
ggplot(data=tool_rate1, aes(x=tools, y=rate_inn)) +
  geom_bar(stat="identity") +
  ggtitle("Innovative Choices by Tool Choice") + 
  xlab("Tool Choice") +
  ylab("Innovative Choice Rate")
```

# Positive Controls

```{r controls}
#source("merge_empanelment_log.R")
source("positive_controls.R")
```

## Competition

+ We hypothesized that groups playing easy games (low competition) would develop a sense of high Collective Self-Efficacy (CSE), while groups playing hard games (high competition) would develop low CSE. + This manipulation showed the desired effect, based on post-game CSE values for each condition. 
  
```{r competitionPlots}
competitionPlots
#glmm3.4.CSE
```

## Uncertainty/Risk

+ Check test items propose obvious choices to test whether participants are paying attention.   
+ Check test items show that tool choices were adequately understood by participants. 

```{r toolControls}
toolControls
```

+ Only `r length(allWrong$matchid)` games failed all three check test items. 

```{r allwrong}
allWrong
```

## Group Composition

We finally check that group randomization was effective in creating groups with the required experimental charachteristics. Our post-hoc analysis of group composition shows that:
+ Average group Tolerance of Ambiguity (TA) was higher in the "high group TA" condition.

```{r groupTAPlots}
groupTAplot
```
+ Average leader TA was higher in the "high leader TA" condition. 

```{r leaderTAPlots}
leaderTAplot
```
+ Average leader Transformational Leadership (TL) score was higher in the "high TL" condition.

```{r leaderTLPlots}
leaderTLplot
```

# General effects

All hypothesis tests and effect size estimations are conducted within a Bayesian framework, using Bayesian Generalized Linear Mixed Models (GLMMs). Because repeated measures from the same game are not independent, all estimations will include a group random effect, and fixed effects for the corresponding independent variables. 

$ln(p/(1-p))_{ij} = \beta_{0} + \beta_{1}X_{j} + \beta_{2}Y_{ij} + \beta_{3} (X_{j}*Y_{ij}) +u_{j} + \epsilon_{ij}$

Where the log odds of the probability of innovation for each decision $i$ in each game $j$ are a function of a constant term $\beta_0$ (intercept); an experimentally manipulated independent 2-level factor $X$ that varies for each game $j$, with unknown coefficients $\beta_1$; an experimentally manipulated independent variable $Y$, that varies for each game $j$ and each measure $i$, with unknown coefficients $\beta_2$; a two-way interaction $(X_j*Y_ij)$ between both experimental variables, with unknown coefficients $\beta_3$; a group random effect $u_j$, and a residual error term $\epsilon_{ij}$. 

We present next the posterior distribution of the coefficients for the full-factorial model, using the equation above. 

```{r glmmoverall}
glmmoverall
posteriorAreas
```

# Hypothesis Testing

We estimate causal effects for all the predictions under each hypothesis using Bayesian applied regression modelling. We quantify the change from prior to posterior model odds based on observed data to compare competing predictions in terms of Bayes factors (see Alston et al., 2005, for a general discussion). 

Posterior predictive distributions and posterior parameter distributions are sampled using Hamiltonian MCMC (e.g. Hoffman & Gelman, 2014), with 3 Markov chains and 10,000 iterations. The posterior probability distributions for each prediction are summarized using the mean and the central 95% interval. Since we are primarily concerned with effect size estimation and model optimization within a Bayesian framework, correction for multiple comparisons do not apply (Gelman, Hill, & Yajima, 2012). 

```{r runload, echo=F, include=F}
source("h1.1.R")


BFs1.1<-read.csv(paste(od, "BFs1.1.csv", sep = '/'))

BFs<-rbind(BFs1.1)
write.csv(BFs, paste(od, "BFs.csv", sep = '/'))
BFs<-read.csv(paste(od, "BFs.csv", sep = '/'))
load (file ="glmm1.1.null")
load (file ="glmm1.1.test")
load (file ="glmm1.1.alt1")
load (file ="glmm1.1.alt2")


```

## Hypothesis 1.1. Intergroup Competition

As an example of hypothesis testing via Bayes Factors, we examine prediction 1.1.1: 

+ 1.1.1. Perceived inter-group competition will show an inverse u-shaped relationship with motivation to innovate: when competition is either too strong or too weak, motivation to innovate will decrease.

The posterior distribution of the coefficients is plotted below, including the three competition levels (Low, Medium, High). The "no competition" condition serves as the reference category. 

```{r h1.1.post, echo=T, include=T}
testnull<-BFs1.1[6]
test.SD<-1.45/3
plotsh1.1.1<-bayesPlotter3 (glmm1.1.test, "h1.1.locomp", "h1.1.medcomp", "h1.1.hicomp", test.SD, "h1.11", "h1.12", "h1.13", testnull)
plotsh1.1.1[[1]]
```

We then estimate the likelihood that the observed data were produced by the hypothesized generating model (1.1.1. inverse u-shaped relationship), and compare that to the likelihood that the observed data were produced by a null model. The Bayes factor is the ratio of the marginal likelihoods of two models, where the marginal likelihood of a model is the probability of the data given a model and quantifies how well the model has predicted the observed data. We calculate the Bayes Factor from the ratio of the likelihood of prediction 1.1.1. to the alternative prediction. The resulting Bayes Factor (BF = `r testnull`) indicates the support for h1.1.1 over the null (BF = 1 indicates no preference, BF>10 indicates strong preference for h1.1.1, BF<0.1 indicates strong preference for h1.1.2). 

```{r h1.1.test, include=T}
plotsh1.1.1[[2]]
```

+ 1.1.2. Increased levels of perceived intergroup competition will decrease group motivation to innovate.

```{r h1.1.alt1, include=T}
plotIters<-nIter*1.5
draws <- as.data.frame(glmm1.1.alt1)
a <- rnorm(plotIters, mean=logodds[["h1.1.medcomp"]], sd=test.SD)
b <- rnorm(plotIters, mean=0, sd=test.SD)
c <- rnorm(plotIters, mean=logodds[["h1.1.locomp"]], sd=test.SD)
d <- draws[["h1.11"]]
e <- draws[["h1.12"]]
f <- draws[["h1.13"]]
plotdf <- data.frame(value=c(a, b, c, d, e, f), 
                     Distribution=c(rep("Prior", plotIters*3),
                                    rep("Posterior", plotIters*3)), 
                     Level=c(rep("h1.1.locomp", plotIters),
                             rep("h1.1.medcomp", plotIters),
                             rep("h1.1.hicomp", plotIters), 
                             rep("h1.1.locomp", plotIters),
                             rep("h1.1.medcomp", plotIters),
                             rep("h1.1.hicomp", plotIters)))
frame.posterior<-subset(plotdf, Distribution=="Posterior")
alt1null<-BFs1.1[7]
ggplot(plotdf, aes(value, fill=Level, linetype=Distribution)) + 
  geom_density(alpha=0.4) + 
  scale_x_continuous(limits = c(-5, 5)) + 
  scale_y_continuous(limits = c(0, 5)) +
  annotate("text", x=2, y=1.7, label = paste(" Alt1 vs Null BF = ", sprintf("%0.2f", alt1null))) +
  geom_vline(xintercept = 0, linetype="dashed")
```
+ 1.1.3. Increased levels of perceived intergroup competition will increase group motivation to innovate.

```{r h1.1.alt2, include=T}
draws <- as.data.frame(glmm1.1.alt2)
a <- rnorm(plotIters, mean=logodds[["h1.1.locomp"]], sd=test.SD)
b <- rnorm(plotIters, mean=0, sd=test.SD)
c <- rnorm(plotIters, mean=logodds[["h1.1.medcomp"]], sd=test.SD)
d <- draws[["h1.11"]]
e <- draws[["h1.12"]]
f <- draws[["h1.13"]]
plotdf <- data.frame(value=c(a, b, c, d, e, f), 
                     Distribution=c(rep("Prior", plotIters*3),
                                    rep("Posterior", plotIters*3)), 
                     Level=c(rep("h1.1.locomp", plotIters),
                             rep("h1.1.medcomp", plotIters),
                             rep("h1.1.hicomp", plotIters), 
                             rep("h1.1.locomp", plotIters),
                             rep("h1.1.medcomp", plotIters),
                             rep("h1.1.hicomp", plotIters)))
frame.posterior<-subset(plotdf, Distribution=="Posterior")
alt2null<-BFs1.1[8]
ggplot(plotdf, aes(value, fill=Level, linetype=Distribution)) + 
  geom_density(alpha=0.4) + 
  scale_x_continuous(limits = c(-5, 5)) + 
  scale_y_continuous(limits = c(0, 5)) +
  annotate("text", x=2, y=1.7, label = paste(" Alt2 vs Null BF = ", sprintf("%0.2f", alt2null))) +
  geom_vline(xintercept = 0, linetype="dashed")
```

The comparisons indicate overwhelming support for the null hypothesis of no effect of competition on motivation to innovate. The "Low competition" condition was however associated with a consistent decrease in group motivation to innovate, although the effect was smaller than any of our predictions. 

```{r BFs1.1, include=T}
BFs1.1<-t(BFs1.1[3:8])
colnames(BFs1.1)<- c("Bayes Factor")
kable(BFs1.1, caption = "Bayes Factors - h1.1", digits = 2)
```

# Machine Learning

Since the aim of the NGS2 program is being able to quickly and reliably single models that can predict and explain group innovation, we conduct a model robustness check by comparing the model-based predictions of a full Bayesian GLMM with the data-driven predictions of a machine learning (ML) approach. ML algorithms can efficiently discover complex dependencies in the data, including non-linear relationships and multiple-order interactions between predictors, which will lead to biased estimates of predictor coefficients and lower overall model fit if left ignored. 

We train a Random Forests model using the caret package in R (R Core Team, 2018), using a random subset of the experimental data including 80% of the cases (stratified by game) to train the model with 5-fold cross-validation, with the remaining 20% of cases put aside in a testing dataset. Out of sample performance of both the ML and Bayesian models will be assessed through a comparison of Receiver Operating Characteristic (ROC) curves, as estimated from the testing dataset. 

```{r RFs, include=F}
# What matters most (random forests)

factorialRF <- read.csv(file = paste(od, "gamesData.csv", sep = '/'))
factorialRF$innovate[factorialRF$innovation==0] <- "BAU"
factorialRF$innovate[factorialRF$innovation==1] <- "Innovate"
factorialRF<-data.frame(lapply(factorialRF, factor))
factorialRF <- factorialRF[,-c(6:10, 16:19, 21:24)]
factorialRF <- factorialRF[complete.cases(factorialRF), ]

# Create partition (80/20)
set.seed(12345)
inBuild <- createDataPartition(y=factorialRF$innovate, p=0.80, list=FALSE)
training <- factorialRF[inBuild,]
validation <- factorialRF[-inBuild,]

# Train and tune model with cross-validation

rf.control <- trainControl(method = "cv", number = 5, verboseIter=TRUE, 
                           returnData = TRUE, returnResamp = "all", 
                           summaryFunction=twoClassSummary, classProbs=TRUE)
tunegrid <- expand.grid(.mtry=c(8))
rf.tuned<-train(innovate~., data=training, method="rf", tuneGrid=tunegrid,
                trControl=rf.control, tuneLength=8)
predictions <- predict(object=rf.tuned, validation, type='prob')

# Predictions from Bayesian GLMER model

predsBayesian<-colMeans(posterior_linpred(glmmoverall, transform=TRUE, newdata=validation))
```

The areas under the two correlated ROC curves are shown below. According to the Delong test (1988), as implemented by the roc.test procedure of the pROC package (Robin et al., 2011), the ML approach  outperforms the GLMM approach. 

```{r ROCs, include=T}
combplot1 <- plot.roc(validation$innovate, 
                      predsBayesian,
                     main="Statistical Comparison of ROC Curves", 
                      percent=TRUE, col="#1c61b6")
combplot2 <- lines.roc(validation$innovate, predictions$Innovate, percent=TRUE, col="orange")

testobj <- roc.test(combplot1, combplot2)
legend("bottomright", 
       legend=c("Bayesian GLMM", 
                "Random Forests"), 
       col=c("#1c61b6", 
             "orange"), 
       lwd=2, cex = 0.9)
text(50, 40, labels=paste("p-value =", format.pval(testobj$p.value, digits =3, eps= 0.001)), adj=c(0, .5))
```

The GLMM model shows an AUC of `r round(combplot1$auc, 1)`, indicating substantial room for improvement in predictions. The ML model in turn obtained an AUC of `r round(combplot2$auc, 1)`, superior to the GLMM model suggesting some potential to enhance explanatory power by incorporating higher-order relationships (e.g. non-linearities and interactions) among the existing variables. Further gains in explanatory power would require new variables. 


# Conclusions

Our results show generally smaller effects than anticipated, with our Bayesian hypothesis testing often favoring the null. Although most effects were smaller than predicted, meaningful non-zero effects were identified for most of our experimental variables. 

## Confirmed Predictions

+	H2.2: Probability Theory: When faced with medium-level risks, group motivation to innovate increases with the expected value of the innovation. 
+	H2.4: Expected Utility Theory: Groups are generally risk-averse, irrespective of differential prospects.
+	H3.5: Allowing groups to communicate has a medium sized effect on the group’s motivation to innovate.

## Meaningful effects 

+	Low competition reduces group motivation to innovate (small effect, -0.4 to -0.6)
+	Negative framing reduces group motivation to innovate (small effect, -0.2 to -0.3)
+	Exogenous uncertainty increases group motivation to innovate (very small effect,0.1 to 0.2)
+	Groups are more risk seeking for gains of low probability (small effect, 0.4 to 0.6)
+	Groups are more risk averse for high probability gains (-0.5 to -0.6)
+	Low instrumentality reduces group motivation to innovate (small effect, -0.3 to -0.4)
+	Group tolerance of ambiguity increases group motivation to innovate (very small effect, 0.1 to 0.3)

## Near-zero effects

+	Leader  Tolerance of Ambiguity
+	Group Status and Legitimacy
+	Collective Self-efficacy

## Inconclusive effects

+	Expectancy: the effect of expectancy was in the opposite direction than predicted, suggesting groups may only be reacting to part of the information available. Stronger manipulations and positive controls are required.
+	Communication on expected value: the effect of prompting teams to consider the expected value of an innovation could not be discerned from the effect of  communication alone. Stronger manipulations and positive controls are required.

## Explanatory power

Our explanatory power was moderate, with an AUC of `r round(combplot1$auc, 1)`. The ML-based approach obtained a stronger fit, which suggests potential for improvement by exploring non-linear relationships, first-order interactions and higher-order interactions between predictors. Any further gains in predictive power would require new data collection with additional variables.
